{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "Script plots a PCA for the observed data, alongside a PCA using simulated data, utilising the medians of the priors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "All imports occur here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sim.model\n",
    "from sim import sum_stats as ss\n",
    "import time\n",
    "import tskit\n",
    "import msprime\n",
    "import allel\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose parameters\n",
    "Choose some parameters so it runs relatively quickly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_features = sim.model.SeqFeatures(length=int(20e6), recombination_rate=1.8e-8, mutation_rate=6e-8)\n",
    "\n",
    "slim_parameters = {\n",
    "    'pop_size_domestic_1': 2000,  # Population sizes are diploid.\n",
    "    'pop_size_wild_1': 2000,\n",
    "    'pop_size_captive': 70,\n",
    "    'mig_rate_captive': 0.005,  # Migration from wild -> captive\n",
    "    'mig_length_wild': 34,\n",
    "    'mig_rate_wild': 0.008,  # Rate of migration from domestic -> wildcats\n",
    "    'captive_time': 28,  # Time captive population established in SLiM\n",
    "    }\n",
    "\n",
    "recapitate_parameters = {\n",
    "        'pop_size_domestic_2': 4000,\n",
    "        'pop_size_wild_2': 4000,\n",
    "        'div_time': 40000,\n",
    "        'mig_rate_post_split': 0.005,\n",
    "        'mig_length_post_split': 5000,\n",
    "        'bottleneck_time_wild': 3000,\n",
    "        'bottleneck_strength_wild': 20000,\n",
    "        'bottleneck_time_domestic': 3000,\n",
    "        'bottleneck_strength_domestic': 20000,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation finished in 7.88 s\n",
      "Command ran: slim -d pop_size_domestic_1=2000 -d pop_size_wild_1=2000 -d pop_size_captive=70 -d mig_rate_captive=0.005 -d mig_length_wild=34 -d mig_rate_wild=0.008 -d captive_time=28 -d length=20000000 -d recombination_rate=1.8e-08  -d decap_trees_filename='\"../output/decap_42.trees\"' -s 40 slim_model.slim\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Run model\n",
    "s = sim.model.WildcatSimulation(seq_features=seq_features, random_seed=42)\n",
    "command = s.slim_command(slim_parameters)\n",
    "decap_trees = s.run_slim(command)\n",
    "demographic_events = s.demographic_model(**recapitate_parameters)\n",
    "tree_seq = s.recapitate(decap_trees, demographic_events)\n",
    "\n",
    "# Print out useful bits and bobs\n",
    "print(\"Simulation finished in {:.2f} s\".format(time.time()-start_time))\n",
    "print(\"Command ran: {}\".format(command))\n",
    "# tree_seq.slim_provenance.model_type = \"WF\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = s.sample_nodes(tree_seq, [5, 30, 10])  # Match number of samples to the WGS data\n",
    "tree_seq = tree_seq.simplify(samples=samples)\n",
    "data = sim.model.collate_results(tree_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate some summary statistics with scikit-allel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wild', 'captive']\n",
      "['domestic', 'captive']\n",
      "['domestic', 'wild']\n"
     ]
    }
   ],
   "source": [
    "pop_names = [\"domestic\", \"wild\", \"captive\", \"all_pops\"]\n",
    "\n",
    "# One-way statistics\n",
    "diversity = {}\n",
    "tajimas_d = {}\n",
    "wattersons_theta = {}\n",
    "observed_heterozygosity = {}\n",
    "expected_heterozygosity = {}\n",
    "\n",
    "for pop in pop_names:\n",
    "    # One-way statistics\n",
    "    diversity[pop] = allel.sequence_diversity(data.positions, data.allele_counts[pop])\n",
    "    wattersons_theta[pop] = allel.watterson_theta(data.positions, data.allele_counts[pop])\n",
    "    tajimas_d[pop] = allel.tajima_d(data.allele_counts[pop], data.positions)\n",
    "    observed_heterozygosity[pop] = allel.heterozygosity_observed(data.genotypes[pop])\n",
    "    expected_heterozygosity[pop] = allel.heterozygosity_expected(data.allele_counts[pop].to_frequencies(), ploidy=2)\n",
    "    \n",
    "    \n",
    "# Two-way statistics\n",
    "divergence = {}\n",
    "fst = {}\n",
    "f2 = {}\n",
    "    \n",
    "for comparison in [\"domestic_wild\", \"domestic_captive\", \"wild_captive\"]:  # Could be possible to add popA vs popB & popC\n",
    "    p = comparison.split(\"_\")\n",
    "    divergence[comparison] = allel.sequence_divergence(data.positions,\n",
    "                                                       data.allele_counts[p[0]],\n",
    "                                                       data.allele_counts[p[1]])\n",
    "    \n",
    "    num, den = allel.hudson_fst(data.allele_counts[p[0]], data.allele_counts[p[1]])\n",
    "    fst[comparison] = np.sum(num)/np.sum(den)\n",
    "    f2 [comparison] = allel.patterson_f2(data.allele_counts[p[0]], data.allele_counts[p[1]])\n",
    "\n",
    "\n",
    "# Three-way statistics\n",
    "f3 = {}    \n",
    "    \n",
    "# Three-way statistics\n",
    "pop_names.remove(\"all_pops\")\n",
    "for pop in pop_names:\n",
    "    remaining_pops = [p for p in pop_names if p is not pop]\n",
    "    print(remaining_pops)\n",
    "    T, B = allel.patterson_f3(data.allele_counts[pop],\n",
    "                              data.allele_counts[remaining_pops[0]],\n",
    "                              data.allele_counts[remaining_pops[1]])\n",
    "    f3[pop] = np.sum(T) / np.sum(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'domestic_sfs_mean_1_1': 8095.0,\n",
       " 'domestic_sfs_mean_2_2': 3935.0,\n",
       " 'domestic_sfs_mean_3_3': 2021.0,\n",
       " 'domestic_sfs_mean_4_4': 1475.0,\n",
       " 'domestic_sfs_mean_5_5': 631.0,\n",
       " 'wild_sfs_mean_1_6': 6301.833333333333,\n",
       " 'wild_sfs_mean_7_12': 10706.5,\n",
       " 'wild_sfs_mean_13_18': 9806.166666666666,\n",
       " 'wild_sfs_mean_19_24': 198.5,\n",
       " 'wild_sfs_mean_25_30': 126.5,\n",
       " 'captive_sfs_mean_1_2': 23805.0,\n",
       " 'captive_sfs_mean_3_4': 5962.0,\n",
       " 'captive_sfs_mean_5_6': 4794.0,\n",
       " 'captive_sfs_mean_7_8': 927.0,\n",
       " 'captive_sfs_mean_9_10': 583.5,\n",
       " 'all_pops_sfs_mean_1_9': 4979.444444444444,\n",
       " 'all_pops_sfs_mean_10_18': 661.3333333333334,\n",
       " 'all_pops_sfs_mean_19_27': 12666.333333333334,\n",
       " 'all_pops_sfs_mean_28_36': 553.5555555555555,\n",
       " 'all_pops_sfs_mean_37_45': 81.11111111111111}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_monomorphic = {}\n",
    "sfs_stats = {}\n",
    "\n",
    "for pop in [\"domestic\", \"wild\", \"captive\", \"all_pops\"]:\n",
    "    sfs = allel.sfs_folded(data.allele_counts[pop])\n",
    "    \n",
    "    if pop is not \"all_pops\":\n",
    "        n_monomorphic[pop] = sfs[0] # Monomorphic in subpop\n",
    "\n",
    "    sfs = sfs[1:]\n",
    "    split_sfs = np.array_split(sfs, 5)\n",
    "    bin_means = [array.mean() for array in split_sfs]\n",
    "    labels = []\n",
    "    idx = 1\n",
    "    for array in split_sfs:\n",
    "        labels.append(\"{}_sfs_mean_{}_{}\".format(pop, idx, idx + len(array) - 1))\n",
    "        idx += len(array)\n",
    "    pop_stats = dict(zip(labels, bin_means))\n",
    "    sfs_stats = {**sfs_stats, **pop_stats}\n",
    "\n",
    "sfs_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_names = [\"domestic\", \"wild\", \"captive\", \"all_pops\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-415e17c804d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpop_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"all_pops\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpop_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = [5, 30, 10]\n",
    "nodes = np.array([tree_seq.individual(i).nodes for i in tree_seq.individuals_alive_at(0)])\n",
    "pop = np.array([tree_seq.individual(i).population for i in tree_seq.individuals_alive_at(0)])\n",
    "\n",
    "samples = []\n",
    "pop_num = 0\n",
    "\n",
    "sampled_inds = np.random.choice(np.where(pop==pop_num)[0], replace=False, size=sample_sizes[pop_num])\n",
    "print()\n",
    "\n",
    "np.concatenate(nodes[sampled_inds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample_nodes(tree_seq, sample_sizes).tolist()\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_names = [\"dom\", \"wild\", \"cap\"]\n",
    "nodes = [ind.nodes for ind in tree_seq.individuals()]\n",
    "pop = [pop_names[ind.population] for ind in tree_seq.individuals()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[ind.nodes for ind in tree_seq.individuals()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check tsinfer ancestral state irrelevant toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyslim.make_slim_provenance_dict(\"real_data\",` 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(np.array(genotypes), \"../output/test_genotypes.joblib\")\n",
    "joblib.dump(pos, \"../output/test_pos.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"AB\": [1,2,3], \"AC\": [5,4,5], \"CC\": [5,7,5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[col for col in list(df) if \"A\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = np.loadtxt(\"../data/e3.012.pos\", delimiter=\"\\t\", usecols=1)\n",
    "genotypes = np.loadtxt(\"../data/e3.012\", delimiter=\"\\t\", usecols=range(1, len(positions)+1))\n",
    "genotypes = genotypes.T\n",
    "assert len(positions) == genotypes.shape[0]\n",
    "\n",
    "# For now just assume that missings are ancestral\n",
    "genotypes[genotypes == -1] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cam read in with scikit allel but genotypes looks dodge\n",
    "callset = allel.read_vcf(\"../data/e3.vcf\")\n",
    "pos = callset[\"variants/POS\"]\n",
    "genotypes = allel.GenotypeArray(callset[\"calldata/GT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callset[\"samples\"][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_pipeline(genotypes, pos, pop_list):\n",
    "    genotypes, pos = ss.maf_filter(genotypes, pos)\n",
    "    genotypes = genotypes.to_n_alt()  # 012 with ind as cols\n",
    "    genotypes, pos = ss.ld_prune(genotypes, pos)\n",
    "    pca_stats = ss.pca_stats(genotypes, pop_list)\n",
    "    return pca_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_info = pd.read_csv(\"../data/e3_sample_info.csv\", usecols=[\"NAME\", \"SOURCE\"])\n",
    "\n",
    "# Ensure that individuals are in same order (after 012 conversion)\n",
    "assert np.all(sample_info[\"NAME\"] == np.loadtxt(\"../data/e3.012.indv\", dtype=str))\n",
    "\n",
    "pca_pipeline(genotypes, pos, sample_info[\"SOURCE\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsinfer\n",
    "\n",
    "with tsinfer.SampleData(sequence_length=6) as sample_data:\n",
    "    sample_data.add_site(0, [0, 1, 0, 0, 0], [\"A\", \"T\"])\n",
    "    sample_data.add_site(1, [0, 0, 0, 1, 1], [\"G\", \"C\"])\n",
    "    sample_data.add_site(2, [0, 1, 1, 0, 0], [\"C\", \"A\"])\n",
    "    sample_data.add_site(3, [0, 1, 1, 0, 0], [\"G\", \"C\"])\n",
    "    sample_data.add_site(4, [0, 0, 0, 1, 1], [\"A\", \"C\"])\n",
    "    sample_data.add_site(5, [0, 1, 2, 0, 0], [\"T\", \"G\", \"C\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_pipeline(genotypes, pos, pop_list):\n",
    "    genotypes, pos = ss.maf_filter(genotypes, pos)\n",
    "    genotypes = genotypes.to_n_alt()  # 012 with ind as cols\n",
    "    genotypes, pos = ss.ld_prune(genotypes, pos)\n",
    "    pca_stats = ss.pca_stats(genotypes, pop_list)\n",
    "    return pca_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_functions = [\n",
    "    ss.tskit_stats(tree_seq, samples),\n",
    "    ss.afs_stats(tree_seq, samples),\n",
    "    ss.r2_stats(tree_seq, samples, [0, 1e6, 2e6, 4e6], labels=[\"0_1Mb\", \"1_2Mb\", \"2_4MB\"]),\n",
    "    ss.roh_stats(genotypes, pos, pop_list, seq_features.length),\n",
    "    pca_pipeline(genotypes, pos, pop_list),\n",
    "]\n",
    "\n",
    "stats_dict = {\"random_seed\": sim.random_seed}  # Random seed acts as ID\n",
    "\n",
    "for func in summary_functions:\n",
    "    stat = func\n",
    "    stats_dict = {**stats_dict, **stat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caluculate summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sim.sample_nodes(tree_seq, [4, 45, 46])  # Match number of samples to the WGS data\n",
    "tree_seq = tree_seq.simplify(samples=np.concatenate(samples))\n",
    "\n",
    "# Calculate summary statistics\n",
    "def pca_pipeline(genotypes, pos):\n",
    "    genotypes, pos = ss.maf_filter(genotypes, pos)\n",
    "    genotypes = genotypes.to_n_alt()  # 012 with ind as cols\n",
    "    genotypes, pos = ss.ld_prune(genotypes, pos)\n",
    "    pca_stats = ss.pca_stats(genotypes)\n",
    "    return pca_stats\n",
    "\n",
    "genotypes = ss.genotypes(tree_seq)  # scikit-allel format\n",
    "pos = ss.positions(tree_seq)\n",
    "\n",
    "# Using a list to call function in for loop so we can use try/except (in case any functions fail)\n",
    "summary_functions = [\n",
    "    sum_stats.tskit_stats(),\n",
    "    sum_stats.afs_stats(),\n",
    "    sum_stats.r2_stats(),\n",
    "    sum_stats.roh_stats(genotypes, pos),\n",
    "    pca_pipeline(genotypes, pos),\n",
    "]\n",
    "\n",
    "stats_dict = {\"random_seed\": sim.random_seed}  # Random seed acts as ID\n",
    "\n",
    "for func in summary_functions:\n",
    "    stat = func\n",
    "    stats_dict = {**stats_dict, **stat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_stats = {'domestic_roh_cov_median': 0.9996666, 'domestic_roh_cov_iqr': 0.00022224444444440827, 'wild_roh_cov_median': 0.6211887222222223, 'wild_roh_cov_iqr': 0.19288330555555555, 'captive_roh_cov_median': 0.8555888222222222, 'captive_roh_cov_iqr': 0.10507222222222223}\n",
    "coverage_stats[\"all_pops_roh_cov_median\"] = np.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(prior_df[[\"mig_rate_wild\", \"mig_rate_post_split\"]]<=1) & np.all(prior_df[[\"mig_rate_wild\", \"mig_rate_post_split\"]]>=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate ROH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below seems fine but we should probably filter minor alleles. With this a single mutation breaks a ROH... I think that is ok? Presumably v. informative for PODs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sim.sample_nodes(tree_seq, [4, 45, 46])  # Match number of samples to the SNP data\n",
    "tree_seq = tree_seq.simplify(samples=np.concatenate(samples))\n",
    "sum_stats = SummaryStatistics(tree_seq, sim)\n",
    "genotypes = sum_stats.sampled_genotypes()\n",
    "is_homo = genotypes[:,:,0] == genotypes[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roh_id = pd.DataFrame(np.cumsum(is_homo == False, axis=0))  # Increment ID with each heterozygote\n",
    "roh_id[\"position\"] = sim_tools.positions(tree_seq)\n",
    "df = roh_id.melt(id_vars=\"position\", var_name=\"individual\", value_name=\"roh_id\")\n",
    "df = df.groupby([\"individual\", \"roh_id\"])[\"position\"].max().reset_index()\n",
    "df[\"roh_length\"] = df.groupby('individual')['position'].diff(1)\n",
    "df = df.dropna()  # Drops first \"ROH\" (as no previous heterozygote)\n",
    "df = df.drop(columns = [\"position\", \"roh_id\"])\n",
    "# pd.DataFrame({\"population\": sum_stats.individual_pop_list, \"id\": range(0, len(sum_stats.individual_pop_list))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take a sample and get the genotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sim.sample_nodes(tree_seq, [4, 45, 46])  # Match number of samples to the SNP data\n",
    "tree_seq = tree_seq.simplify(samples=np.concatenate(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genotypes = ss.genotypes(tree_seq)\n",
    "pos = ss.positions(tree_seq)\n",
    "pop_list = ss.pop_list(tree_seq)\n",
    "samples = ss.sampled_nodes(tree_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for LD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ld(gn, title):\n",
    "    m = allel.rogers_huff_r(gn) ** 2\n",
    "    ax = allel.plot_pairwise_ld(m)\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ld(genotypes[:1000].to_n_alt(), 'Pairwise LD.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter singletons and SNPs in LD\n",
    "SNPs in LD can bias PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genotypes, pos = ss.maf_filter(genotypes, pos)\n",
    "genotypes, pos = ss.ld_prune(genotypes.to_n_alt(), pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ld(genotypes[:1000], 'Pairwise LD after pruning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_population = np.asarray([\"domestic\"]*4 + [\"wild\"]*45 + [\"captive\"]*46)\n",
    "populations = [\"domestic\", \"wild\", \"captive\"]\n",
    "pop_colours = [\"#FF0000\", \"#FFA500\", \"#0000FF\"]\n",
    "\n",
    "# Simulated data pca\n",
    "coords, model = allel.pca(genotypes, n_components=10, scaler='patterson')\n",
    "sim_df = pd.DataFrame({\"pc1\": coords[:, 0], \"pc2\": coords[:, 1],\n",
    "                       \"population\": sample_population, \"simulated_or_observed\": \"simulated\"})\n",
    "\n",
    "# Real data pca\n",
    "real_genotypes = np.loadtxt(\"../data/snps.012\", delimiter=\" \", skiprows=1)\n",
    "real_genotypes = real_genotypes[:,1:].transpose()  # Get rid of index and convert individuals to columns\n",
    "coords, model = allel.pca(real_genotypes, n_components=2, scaler='patterson')\n",
    "real_df = pd.DataFrame({\"pc1\": coords[:, 0], \"pc2\": coords[:, 1],\n",
    "                   \"population\": sample_population, \"simulated_or_observed\": \"observed\"})\n",
    "\n",
    "# Combined data\n",
    "combined_df = sim_df.append(real_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='darkgrid', font_scale=1.3)\n",
    "\n",
    "g = sns.relplot(x=\"pc1\", y=\"pc2\",\n",
    "                row=\"simulated_or_observed\", hue=\"population\",\n",
    "                kind=\"scatter\", data=combined_df,\n",
    "                facet_kws=dict(sharex=False, sharey=False),\n",
    "                aspect=1.4)\n",
    "\n",
    "axes = g.axes.flatten()\n",
    "axes[0].set_title(\"Simulated\")\n",
    "axes[1].set_title(\"Observed\")\n",
    "\n",
    "#g.savefig(\"../plots/simulated_vs_observed_pca.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.read_csv(\"../output/summary_stats.csv\")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_sum_stats = scaler.fit_transform(stats)\n",
    "scaler.inverse_transform(scaled_sum_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
